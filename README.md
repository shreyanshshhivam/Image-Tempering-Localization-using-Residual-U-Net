# Image-Tempering-Localization-using-Residual-U-Net
 Overview of the Project

This project focuses on detecting and localizing tampered regions in digital images using a Residual U-Net segmentation model.
The goal is to identify manipulated areas such as splicing, copy-move, or object insertion with pixel-level accuracy.

The model is trained on the Realistic Tampering Dataset, containing pristine images, tampered images, and ground-truth masks.


---

 Features

ğŸ” Pixel-level tampering localization

ğŸ§  Residual U-Net architecture for deeper feature extraction

ğŸ“Š Dice + BCE loss for accurate segmentation

ğŸ”„ Data augmentation (flips, resizing)

ğŸ–¥ GPU-accelerated training support

ğŸ“ˆ Evaluation metrics â€“ IoU & Dice Score

ğŸ’¾ Saves best, latest, and final trained model weights

ğŸ“‚ Modular dataset loader for real-world tampering datasets



---

ğŸ›  Technologies / Tools Used

Python 3.10+

PyTorch

Torchvision

NumPy

Pillow (PIL)

TQDM

Matplotlib (optional for visualization)

Realistic-Tampering-Dataset (Canon, Nikon, Sony models)



---

ğŸš€ Steps to Install & Run the Project

1ï¸âƒ£ Clone or Download the Repository

git clone <your-repo-link>
cd tamper-localization

2ï¸âƒ£ Install Dependencies

Create an environment and install required libraries:

pip install torch torchvision pillow numpy tqdm

(Optional GPU version)

pip install torch --index-url https://download.pytorch.org/whl/cu121

3ï¸âƒ£ Download the Dataset

Place your dataset in this structure:

data-images/
   Nikon_D90/
      pristine/
      tampered-realistic/
      ground-truth/
   Canon_60D/
   Nikon_D7000/
   Sony_A57/

4ï¸âƒ£ Run Training Script

python train.py

This will:

Train for 30 epochs

Save: best_resunet.pth, last_resunet.pth, final_resunet.pth


5ï¸âƒ£ Inference on Test Image

python inference.py --img path/to/image.jpg --model final_resunet.pth


---

ğŸ§ª Instructions for Testing

1. After training, load the trained model:



model.load_state_dict(torch.load("best_resunet.pth"))

2. Pass your image through the preprocessing pipeline (resize â†’ tensor â†’ normalize)


3. Run:



pred = model(image_tensor.unsqueeze(0))

4. Apply threshold 0.5:



mask = (torch.sigmoid(pred) > 0.5).float()

5. Visualize the mask overlay.
6.
